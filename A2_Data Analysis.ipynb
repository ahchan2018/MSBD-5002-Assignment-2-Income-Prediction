{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/trainFeatures.csv')\n",
    "test = pd.read_csv('./data/testFeatures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples=34189, test_samples=14653\n",
      "train features=14, test_features=14\n"
     ]
    }
   ],
   "source": [
    "train_samples = train.shape[0]\n",
    "test_samples = test.shape[0]\n",
    "train_features = train.shape[1]\n",
    "test_features = test.shape[1]\n",
    "print(\"train samples={}, test_samples={}\".format(train_samples, test_samples))\n",
    "print(\"train features={}, test_features={}\".format(train_features, test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the data containing missing value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_miss = train.isna().any()\n",
    "test_mis = test.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "workclass         False\n",
       "fnlwgt            False\n",
       "education         False\n",
       "education-num     False\n",
       "Marital-status    False\n",
       "occupation        False\n",
       "relationship      False\n",
       "race              False\n",
       "sex               False\n",
       "capital-gain      False\n",
       "capital-loss      False\n",
       "hours-per-week    False\n",
       "native-country    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_mis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Variable Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For Continus Variables age, fnlwgt,education-num,capital-gain,capital-loss,hours-per-week, we need to transform them into categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max age=90, min_age=17, avg_age=38\n"
     ]
    }
   ],
   "source": [
    "age = train['age'].values\n",
    "max_age = age.max()\n",
    "min_age = age.min()\n",
    "avg_age = int(age.mean())\n",
    "print('max age={}, min_age={}, avg_age={}'.format(max_age, min_age, avg_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to general knowledge, It would be better if we transform the age into amature, adult, wrinkly, old, and long-life-age. here is the range for different age people\n",
    "- amature: 0~18\n",
    "- adult: 18~30\n",
    "- wrinkly 30~55\n",
    "- old: 55~70\n",
    "- long-life-age: 70~90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Transform fnlwgt. Final weight, this is the number of people the census believes the entry represents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_fnlwgt=1490400, min_fnlwgt=12285, mean_fnlwgt=189792, fnlwgt_gap=1478115\n"
     ]
    }
   ],
   "source": [
    "fnlwgt = train['fnlwgt']\n",
    "max_fnlwgt = fnlwgt.max()\n",
    "min_fnlwgt = fnlwgt.min()\n",
    "avg_fnlwgt = int(fnlwgt.mean())\n",
    "differ_fnlwgt = max_fnlwgt-min_fnlwgt\n",
    "print('max_fnlwgt={}, min_fnlwgt={}, mean_fnlwgt={}, fnlwgt_gap={}'.format(max_fnlwgt, min_fnlwgt, avg_fnlwgt, differ_fnlwgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the region by Quartile Q1,Q2,Q3 and double outlier\n",
    "#### $outlier_{up} = Q3+1.5IQR$\n",
    "#### $outlier_{down} = Q1-1.5IQR$\n",
    "#### $IQR = Q3-Q1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_region(soted_vector):\n",
    "    samples = soted_vector.shape[0]\n",
    "    Q1 = soted_vector[int(0.25*samples)]\n",
    "    Q2 = soted_vector[int(0.5*samples)]\n",
    "    Q3 = soted_vector[int(0.75*samples)]\n",
    "    IQR = Q3-Q1\n",
    "    outlier_up = Q3+1.5*IQR\n",
    "    outlier_down = Q1-1.5*IQR\n",
    "    \n",
    "    return Q1, Q2,Q3,outlier_up,outlier_down\n",
    "Q1,Q2,Q3,outlier_up,outlier_down = split_region(np.sort(fnlwgt.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117847 178449 237624 417289.5 -61818.5\n"
     ]
    }
   ],
   "source": [
    "print(Q1,Q2,Q3,outlier_up,outlier_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see the variety of the Q values and outliers, we conclude that we could transform the whole 'fnlwgt' into 6 region split by Q1,Q2,Q3,outlier_up and outlier_down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform education-num, Highest level of education in numerical form\n",
    "##### Seems like it is categorial, we can check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n"
     ]
    }
   ],
   "source": [
    "education_num = train['education-num']\n",
    "education_num_unique = np.unique(education_num)\n",
    "print(education_num_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### its value elements are limited, so we don't have to transfer them into categorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform captial-gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,   114,   401,   594,   914,   991,  1055,  1086,  1111,\n",
       "        1151,  1173,  1264,  1409,  1424,  1455,  1471,  1506,  1639,\n",
       "        1731,  1797,  1831,  1848,  2009,  2036,  2050,  2062,  2105,\n",
       "        2174,  2176,  2202,  2228,  2290,  2329,  2346,  2354,  2387,\n",
       "        2407,  2414,  2463,  2538,  2580,  2597,  2635,  2653,  2829,\n",
       "        2885,  2907,  2936,  2961,  2964,  2977,  2993,  3103,  3137,\n",
       "        3273,  3325,  3411,  3418,  3432,  3456,  3464,  3471,  3674,\n",
       "        3781,  3818,  3887,  3908,  3942,  4064,  4101,  4386,  4416,\n",
       "        4508,  4650,  4687,  4787,  4865,  4931,  4934,  5013,  5060,\n",
       "        5178,  5455,  5556,  5721,  6360,  6418,  6497,  6514,  6612,\n",
       "        6723,  6767,  6849,  7262,  7298,  7430,  7443,  7688,  7896,\n",
       "        7978,  8614,  9386,  9562, 10520, 10566, 10605, 11678, 13550,\n",
       "       14084, 14344, 15020, 15024, 15831, 20051, 22040, 25124, 25236,\n",
       "       27828, 34095, 41310, 99999], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captial_gain = train['capital-gain']\n",
    "np.unique(captial_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Just like education-num, here the captial-gain's elements are countable, so we don't have to transfer them. But their values are too big to be accepted by the model so we need to do a hash process, like 114--->hash->1, hash it to a smaller number, which will be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfor captial-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  155,  213,  323,  419,  625,  653,  810,  880,  974, 1092,\n",
       "       1138, 1258, 1340, 1380, 1408, 1411, 1429, 1485, 1504, 1510, 1539,\n",
       "       1564, 1573, 1579, 1590, 1594, 1602, 1617, 1628, 1648, 1651, 1668,\n",
       "       1669, 1672, 1719, 1721, 1726, 1740, 1741, 1755, 1762, 1816, 1825,\n",
       "       1844, 1848, 1870, 1876, 1887, 1902, 1911, 1944, 1974, 1977, 1980,\n",
       "       2001, 2002, 2042, 2051, 2057, 2080, 2129, 2149, 2163, 2174, 2179,\n",
       "       2205, 2206, 2231, 2238, 2246, 2258, 2267, 2282, 2339, 2352, 2377,\n",
       "       2392, 2415, 2444, 2457, 2465, 2467, 2472, 2489, 2547, 2559, 2603,\n",
       "       2754, 2824, 3004, 3175, 3683, 3770, 3900, 4356], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captial_loss = train['capital-loss']\n",
    "np.unique(captial_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same as captial-gain, hash it too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform hours-per-week, hours-worked-per-week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 88,\n",
       "       89, 90, 91, 92, 94, 95, 96, 97, 98, 99], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours_per_week = train['hours-per-week']\n",
    "np.unique(hours_per_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Just like the variable above just don't need to be hashed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the rest features(variables), nominal or unnominal, we are going to replace them by different numbers so that model could use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
